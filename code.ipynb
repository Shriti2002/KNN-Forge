{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0Fx_f2JwSEh",
        "outputId": "eaddf9bf-42fb-417b-a96c-4f769654f1ce"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from scipy.stats import ttest_rel\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "#Performing k-fold cross-validation by splitting the dataset from scratch.\n",
        "def performing_k_number_of_folds(X, y, k, random_state=None):\n",
        "    if random_state is not None:\n",
        "        np.random.seed(random_state)\n",
        "    number_of_samples = len(X)\n",
        "    indices_of_samples = np.arange(number_of_samples)\n",
        "    np.random.shuffle(indices_of_samples)\n",
        "\n",
        "    sizes_of_folds = np.full(k, number_of_samples // k, dtype=int)\n",
        "    sizes_of_folds[: number_of_samples % k] += 1\n",
        "\n",
        "    array_of_folds = []\n",
        "    current = 0\n",
        "    for fold_size in sizes_of_folds:\n",
        "        start, stop = current, current + fold_size\n",
        "        test_idx = indices_of_samples[start:stop]\n",
        "        train_idx = np.concatenate((indices_of_samples[:start], indices_of_samples[stop:]))\n",
        "        array_of_folds.append((train_idx, test_idx))\n",
        "        current = stop\n",
        "    return array_of_folds\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v1WGCndwfN6g"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dataset Loaders + Preprocessing\n",
        "def prepare_dataset(dataset, scale_data=False):\n",
        "\n",
        "    X = dataset.data.features\n",
        "    y = dataset.data.targets\n",
        "\n",
        "    # Converting the dataset into a DataFrame to make column-based operations easier.\n",
        "    if not isinstance(X, pd.DataFrame):\n",
        "        X = pd.DataFrame(X)\n",
        "    else:\n",
        "        X = X.copy()\n",
        "\n",
        "    if isinstance(y, (pd.Series, pd.DataFrame)):\n",
        "        y = y.values.ravel()\n",
        "\n",
        "\n",
        "\n",
        "    # Removing any rows where either input features (X) or target labels (y) contain missing values.\n",
        "    X[\"__target__\"] = y\n",
        "    X.dropna(axis=0, inplace=True)\n",
        "    y = X[\"__target__\"].values\n",
        "    X.drop(columns=[\"__target__\"], inplace=True)\n",
        "\n",
        "    # Treating features with 'object' or 'category' data types as categorical variables.\n",
        "    cat_cols = [col for col in X.columns\n",
        "                if X[col].dtype == \"object\" or str(X[col].dtype) == \"category\"]\n",
        "\n",
        "    # Applying one-hot encoding to convert categorical features into a numerical format.\n",
        "    X = pd.get_dummies(X, columns=cat_cols, drop_first=False)\n",
        "\n",
        "    # Standardizing or normalizing the data to ensure consistent scaling.\n",
        "    if scale_data:\n",
        "        scaler = StandardScaler()\n",
        "        X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "    # Encoding the target variable (y) if itâ€™s a non-numeric type, making it suitable for modeling.\n",
        "    if y.dtype.kind not in ('i', 'f'):\n",
        "        le = LabelEncoder()\n",
        "        y = le.fit_transform(y)\n",
        "\n",
        "    X = X.values.astype(float)\n",
        "    y = y.astype(int)\n",
        "\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "zMldrf0hx6vH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pHuY8-vvpYIV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_breast_cancer_data(scale_data=False):\n",
        "    dataset = fetch_ucirepo(id=14)\n",
        "    return prepare_dataset(dataset, scale_data=scale_data)\n",
        "\n",
        "\n",
        "def load_hayes_roth_data(scale_data=False):\n",
        "    dataset = fetch_ucirepo(id=44)\n",
        "    return prepare_dataset(dataset, scale_data=scale_data)\n",
        "\n",
        "\n",
        "def load_car_eval_data(scale_data=False):\n",
        "    dataset = fetch_ucirepo(id=19)\n",
        "    return prepare_dataset(dataset, scale_data=scale_data)\n"
      ],
      "metadata": {
        "id": "wPGHvz7SyFW7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN Variant Implementations (from scratch)\n",
        "\n",
        "# Simple KNN\n",
        "class BasicKNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def _euclidean_distance(self, a, b):\n",
        "        return np.sqrt(np.sum((a - b)**2))\n",
        "\n",
        "    def _predict_single(self, x):\n",
        "        # Calculating distances between the query point and all data points.\n",
        "        distances = np.array([self._euclidean_distance(x, x_train)\n",
        "                              for x_train in self.X_train])\n",
        "        # Identifying the k-nearest neighbors based on computed distances.\n",
        "        k_indices = distances.argsort()[:self.k]\n",
        "        # Assigning a label based on the majority vote among the nearest neighbors.\n",
        "        k_labels = self.y_train[k_indices]\n",
        "        return Counter(k_labels).most_common(1)[0][0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_single(x) for x in X])\n",
        "\n"
      ],
      "metadata": {
        "id": "K_Kcy9GLyKVy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Kernel KNN\n",
        "class KernelBasedKNN:\n",
        "    def __init__(self, k=3, kernel=None, bandwidth=1.0):\n",
        "        self.k = k\n",
        "        self.bandwidth = bandwidth\n",
        "        if kernel is None:\n",
        "            self.kernel = lambda d, h: np.exp(-(d**2)/(2*(h**2)))\n",
        "        else:\n",
        "            self.kernel = kernel\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def _euclidean_distance(self, a, b):\n",
        "        return np.sqrt(np.sum((a - b)**2))\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = []\n",
        "        for x in X:\n",
        "            distances = np.array([self._euclidean_distance(x, x_train)\n",
        "                                  for x_train in self.X_train])\n",
        "            k_indices = distances.argsort()[:self.k]\n",
        "            k_distances = distances[k_indices]\n",
        "\n",
        "            #Applying kernel functions to compute weights for neighbors based on distance.\n",
        "            weights = self.kernel(k_distances, self.bandwidth)\n",
        "\n",
        "            # Using a weighted voting mechanism, where closer points have a higher influence.\n",
        "            vote_scores = {}\n",
        "            for idx, w in zip(k_indices, weights):\n",
        "                label = self.y_train[idx]\n",
        "                vote_scores[label] = vote_scores.get(label, 0) + w\n",
        "\n",
        "            # Selecting the label with the highest accumulated weight as the final prediction.\n",
        "            pred_label = max(vote_scores.items(), key=lambda item: item[1])[0]\n",
        "            preds.append(pred_label)\n",
        "        return np.array(preds)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZsRMMKnkyOk6"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluation Functions\n",
        "def test_basic_knn(X, y, k_neighbors=3, num_folds=10):\n",
        "    folds = perform_k_fold_split(X, y, num_folds, random_state=42)\n",
        "    accs_own, accs_sk = [], []\n",
        "    for train_idx, test_idx in folds:\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        # Our BasicKNN\n",
        "        knn_own = BasicKNN(k=k_neighbors)\n",
        "        knn_own.fit(X_train, y_train)\n",
        "        pred_own = knn_own.predict(X_test)\n",
        "        accs_own.append(np.mean(pred_own == y_test))\n",
        "\n",
        "        # Scikit-learn KNN\n",
        "        knn_sk = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
        "        knn_sk.fit(X_train, y_train)\n",
        "        pred_sk = knn_sk.predict(X_test)\n",
        "        accs_sk.append(np.mean(pred_sk == y_test))\n",
        "\n",
        "    return np.array(accs_own), np.array(accs_sk)\n",
        "\n"
      ],
      "metadata": {
        "id": "5H7wUgbmySAi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_kernel_knn(X, y, k_neighbors=3, num_folds=10, bandwidth=1.0):\n",
        "    folds = perform_k_fold_split(X, y, num_folds, random_state=42)\n",
        "    accs_own, accs_sk = [], []\n",
        "\n",
        "    # matching Gaussian kernel for scikit-learn\n",
        "    def sk_kernel(dist_array):\n",
        "        return np.exp(-(dist_array**2) / (2 * bandwidth**2))\n",
        "\n",
        "    for train_idx, test_idx in folds:\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        # Our KernelBasedKNN\n",
        "        knn_own = KernelBasedKNN(k=k_neighbors, bandwidth=bandwidth)\n",
        "        knn_own.fit(X_train, y_train)\n",
        "        pred_own = knn_own.predict(X_test)\n",
        "        accs_own.append(np.mean(pred_own == y_test))\n",
        "\n",
        "        # Scikit-learn KNN with custom kernel weights\n",
        "        knn_sk = KNeighborsClassifier(n_neighbors=k_neighbors, weights=sk_kernel)\n",
        "        knn_sk.fit(X_train, y_train)\n",
        "        pred_sk = knn_sk.predict(X_test)\n",
        "        accs_sk.append(np.mean(pred_sk == y_test))\n",
        "\n",
        "    return np.array(accs_own), np.array(accs_sk)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uEd4wnZXyWY7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Performing 10-fold cross-validation to evaluate model performance.\n",
        "# Measuring accuracy and using a paired t-test for statistical comparisons.\n",
        "\n",
        "def execute_single_label_tests(dataset_name, loader, scale_data=True, k_values=[1,3,5,7,9]):\n",
        "    X, y = loader(scale_data=scale_data)\n",
        "\n",
        "    records = []\n",
        "    for variant in [\"BasicKNN\", \"KernelBasedKNN\"]:\n",
        "        for k in k_values:\n",
        "            if variant == \"BasicKNN\":\n",
        "                acc_own, acc_sk = test_basic_knn(X, y, k_neighbors=k, num_folds=10)\n",
        "            else:\n",
        "                acc_own, acc_sk = test_kernel_knn(\n",
        "                    X, y, k_neighbors=k, num_folds=10, bandwidth=1.0\n",
        "                )\n",
        "\n",
        "            mean_own, std_own = np.mean(acc_own), np.std(acc_own)\n",
        "            mean_sk, std_sk = np.mean(acc_sk), np.std(acc_sk)\n",
        "            t_stat, p_val = ttest_rel(acc_own, acc_sk)\n",
        "            interpretation = (\n",
        "                \"Significant difference (p<0.05).\"\n",
        "                if p_val < 0.05 else\n",
        "                \"Not significant (p>=0.05).\"\n",
        "            )\n",
        "\n",
        "            records.append({\n",
        "                \"Dataset_name\": dataset_name,\n",
        "                \"Variants\": variant,\n",
        "                \"k\": k,\n",
        "                \"Mean\": mean_own,\n",
        "                \"Std\": std_own,\n",
        "                \"SKlearn Mean\": mean_sk,\n",
        "                \"SKlearn Std\": std_sk,\n",
        "                \"t-stat\": t_stat,\n",
        "                \"p-value\": p_val,\n",
        "                \"Interpretation\": interpretation\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(records)\n",
        "    print(f\"\\n{dataset_name} (Single-label) Evaluation Summary\")\n",
        "    print(df.round(4))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tWn2UO6SybTa"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    datasets = {\n",
        "        \"Breast Cancer\": load_breast_cancer_data,\n",
        "        \"Hayes-Roth\": load_hayes_roth_data,\n",
        "        \"Car Evaluation\": load_car_eval_data\n",
        "    }\n",
        "\n",
        "    SCALE_DATA = True\n",
        "    K_VALUES = [1, 3, 5, 7, 9]\n",
        "\n",
        "    for name, loader in datasets.items():\n",
        "        execute_single_label_tests(name, loader, scale_data=SCALE_DATA, k_values=K_VALUES)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m56xfkClyfC-",
        "outputId": "c1366bd0-5a5e-427c-b3e5-3dcc608bc23b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Breast Cancer (Single-label) Evaluation Summary\n",
            "    Dataset_name        Variants  k    Mean     Std  SKlearn Mean  \\\n",
            "0  Breast Cancer        BasicKNN  1  0.6538  0.0967        0.6611   \n",
            "1  Breast Cancer        BasicKNN  3  0.6825  0.0787        0.6825   \n",
            "2  Breast Cancer        BasicKNN  5  0.7001  0.0618        0.7001   \n",
            "3  Breast Cancer        BasicKNN  7  0.7147  0.0862        0.7184   \n",
            "4  Breast Cancer        BasicKNN  9  0.7292  0.0651        0.7329   \n",
            "5  Breast Cancer  KernelBasedKNN  1  0.6538  0.0967        0.6611   \n",
            "6  Breast Cancer  KernelBasedKNN  3  0.6754  0.0781        0.6754   \n",
            "7  Breast Cancer  KernelBasedKNN  5  0.6717  0.0684        0.6717   \n",
            "8  Breast Cancer  KernelBasedKNN  7  0.6828  0.0735        0.6828   \n",
            "9  Breast Cancer  KernelBasedKNN  9  0.6828  0.0735        0.6828   \n",
            "\n",
            "   SKlearn Std  t-stat  p-value              Interpretation  \n",
            "0       0.0907 -1.0101   0.3388  Not significant (p>=0.05).  \n",
            "1       0.0787     NaN      NaN  Not significant (p>=0.05).  \n",
            "2       0.0618     NaN      NaN  Not significant (p>=0.05).  \n",
            "3       0.0816 -1.0000   0.3434  Not significant (p>=0.05).  \n",
            "4       0.0602 -1.0000   0.3434  Not significant (p>=0.05).  \n",
            "5       0.0907 -1.0101   0.3388  Not significant (p>=0.05).  \n",
            "6       0.0781     NaN      NaN  Not significant (p>=0.05).  \n",
            "7       0.0684     NaN      NaN  Not significant (p>=0.05).  \n",
            "8       0.0735     NaN      NaN  Not significant (p>=0.05).  \n",
            "9       0.0735     NaN      NaN  Not significant (p>=0.05).  \n",
            "\n",
            "Hayes-Roth (Single-label) Evaluation Summary\n",
            "  Dataset_name        Variants  k    Mean     Std  SKlearn Mean  SKlearn Std  \\\n",
            "0   Hayes-Roth        BasicKNN  1  0.7203  0.1008        0.7198       0.1182   \n",
            "1   Hayes-Roth        BasicKNN  3  0.6516  0.0689        0.6363       0.1010   \n",
            "2   Hayes-Roth        BasicKNN  5  0.3775  0.1001        0.3703       0.0808   \n",
            "3   Hayes-Roth        BasicKNN  7  0.2951  0.0963        0.2956       0.0415   \n",
            "4   Hayes-Roth        BasicKNN  9  0.3099  0.0967        0.3033       0.1237   \n",
            "5   Hayes-Roth  KernelBasedKNN  1  0.7203  0.1008        0.7198       0.1182   \n",
            "6   Hayes-Roth  KernelBasedKNN  3  0.6516  0.0689        0.6742       0.0908   \n",
            "7   Hayes-Roth  KernelBasedKNN  5  0.7110  0.0913        0.7341       0.1107   \n",
            "8   Hayes-Roth  KernelBasedKNN  7  0.4527  0.1331        0.4159       0.1113   \n",
            "9   Hayes-Roth  KernelBasedKNN  9  0.4077  0.0888        0.4242       0.0901   \n",
            "\n",
            "   t-stat  p-value              Interpretation  \n",
            "0  0.0280   0.9783  Not significant (p>=0.05).  \n",
            "1  0.6214   0.5498  Not significant (p>=0.05).  \n",
            "2  0.2974   0.7729  Not significant (p>=0.05).  \n",
            "3 -0.0222   0.9828  Not significant (p>=0.05).  \n",
            "4  0.3220   0.7548  Not significant (p>=0.05).  \n",
            "5  0.0280   0.9783  Not significant (p>=0.05).  \n",
            "6 -0.9820   0.3518  Not significant (p>=0.05).  \n",
            "7 -1.0000   0.3434  Not significant (p>=0.05).  \n",
            "8  1.8503   0.0973  Not significant (p>=0.05).  \n",
            "9 -0.8859   0.3987  Not significant (p>=0.05).  \n",
            "\n",
            "Car Evaluation (Single-label) Evaluation Summary\n",
            "     Dataset_name        Variants  k    Mean     Std  SKlearn Mean  \\\n",
            "0  Car Evaluation        BasicKNN  1  0.6944  0.0327        0.7129   \n",
            "1  Car Evaluation        BasicKNN  3  0.7650  0.0366        0.7546   \n",
            "2  Car Evaluation        BasicKNN  5  0.8223  0.0374        0.8212   \n",
            "3  Car Evaluation        BasicKNN  7  0.8773  0.0315        0.8698   \n",
            "4  Car Evaluation        BasicKNN  9  0.8981  0.0289        0.9039   \n",
            "5  Car Evaluation  KernelBasedKNN  1  0.6944  0.0327        0.7129   \n",
            "6  Car Evaluation  KernelBasedKNN  3  0.7650  0.0366        0.7575   \n",
            "7  Car Evaluation  KernelBasedKNN  5  0.8223  0.0384        0.8171   \n",
            "8  Car Evaluation  KernelBasedKNN  7  0.8588  0.0326        0.8536   \n",
            "9  Car Evaluation  KernelBasedKNN  9  0.8785  0.0266        0.8750   \n",
            "\n",
            "   SKlearn Std  t-stat  p-value              Interpretation  \n",
            "0       0.0285 -1.8637   0.0952  Not significant (p>=0.05).  \n",
            "1       0.0396  0.6917   0.5066  Not significant (p>=0.05).  \n",
            "2       0.0313  0.2341   0.8202  Not significant (p>=0.05).  \n",
            "3       0.0224  0.8609   0.4116  Not significant (p>=0.05).  \n",
            "4       0.0184 -0.8500   0.4173  Not significant (p>=0.05).  \n",
            "5       0.0285 -1.8637   0.0952  Not significant (p>=0.05).  \n",
            "6       0.0362  0.5096   0.6226  Not significant (p>=0.05).  \n",
            "7       0.0320  1.1477   0.2807  Not significant (p>=0.05).  \n",
            "8       0.0257  0.9987   0.3440  Not significant (p>=0.05).  \n",
            "9       0.0223  0.5105   0.6220  Not significant (p>=0.05).  \n"
          ]
        }
      ]
    }
  ]
}